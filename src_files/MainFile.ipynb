{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in c:\\users\\sanya\\anaconda3\\envs\\data-mining\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from ipynb.fs.defs.SiameseModel import Recognizer\n",
    "import logging\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimension = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and target vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 49152)\n",
      "(400, 49152)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "# Loading input and target vectors\n",
    "\n",
    "X1 = np.load('x1.npy')\n",
    "X2 = np.load('x2.npy')\n",
    "Y = np.load('y.npy')\n",
    "\n",
    "# Reshaping the target vectors\n",
    "X1 = X1.reshape( ( X1.shape[0]  , data_dimension**2 * 3  ) ).astype( np.float32 )\n",
    "X2 = X2.reshape( ( X2.shape[0]  , data_dimension**2 * 3  ) ).astype( np.float32 )\n",
    "\n",
    "print( X1.shape )\n",
    "print( X2.shape )\n",
    "print( Y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of siamese model\n",
    "recognizer = Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 79s 1s/step - loss: 0.4891\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 49152)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 49152)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           54243072    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64)           0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 54,243,137\n",
      "Trainable params: 54,243,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Elapsed time acquired for 5 epoch(s) -> 1.3408917864163716 minutes\n"
     ]
    }
   ],
   "source": [
    "# Defining hyper parameters\n",
    "parameters = {\n",
    "    'batch_size' : 6 ,\n",
    "    'epochs' : 5 ,\n",
    "    'callbacks' : None , # [ TensorBoard( log_dir='logs/{}'.format( time.time() ) ) ] ,\n",
    "    'val_data' : None\n",
    "}\n",
    "\n",
    "# Training the siamese model\n",
    "recognizer.fit( [ X1 , X2 ], Y, hyperparameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "recognizer.save_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter images directory path for custom images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\Test_Images\\\n",
      "Enter images directory path for first class images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Chetana\\\n",
      "Enter images directory path for second class images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Prabhleen\\\n",
      "Enter images directory path for second class images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Sanyam\\\n",
      "Enter images directory path for second class images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Taruneesh\\\n"
     ]
    }
   ],
   "source": [
    "# Enter the path name untill 'images' [ Actual images are stored at ...images/sanyam/image0.png]\n",
    "# Here enter the path till the local images\n",
    "# Custom images : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\Test_Images\\\n",
    "# p1 : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Chetana\\\n",
    "# p2 : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Prabhleen\\\n",
    "# p3 : C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Sanyam\\\n",
    "# p4 :  C:\\Users\\sanya\\Desktop\\Calgary\\ENEL645\\Siamese_Face_Project\\Enel645_FaceDetection_SiameseModel\\images_dataset\\Taruneesh\\\n",
    "dir_path_custom_images = input( 'Enter images directory path for custom images : ')\n",
    "dir_path_class1_images = input( 'Enter images directory path for first class images : ')\n",
    "dir_path_class2_images = input( 'Enter images directory path for second class images : ')\n",
    "dir_path_class3_images = input( 'Enter images directory path for second class images : ')\n",
    "dir_path_class4_images = input( 'Enter images directory path for second class images : ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the numpy arrays of all images\n",
    "custom_images = recognizer.prepare_images_from_dir( dir_path_custom_images  )\n",
    "class_1_images = recognizer.prepare_images_from_dir( dir_path_class1_images )\n",
    "class_2_images = recognizer.prepare_images_from_dir( dir_path_class2_images )\n",
    "class_3_images = recognizer.prepare_images_from_dir( dir_path_class3_images )\n",
    "class_4_images = recognizer.prepare_images_from_dir( dir_path_class4_images )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the numpy array of class first images (5, 49152)\n",
      "The shape of the numpy array of class second images (5, 49152)\n",
      "The shape of the numpy array of class second images (5, 49152)\n",
      "The shape of the numpy array of class second images (5, 49152)\n",
      "The shape of the numpy array of custom images (8, 49152)\n"
     ]
    }
   ],
   "source": [
    "# printing shape of all the images\n",
    "print(\"The shape of the numpy array of class first images\", class_1_images.shape)\n",
    "print(\"The shape of the numpy array of class second images\", class_2_images.shape)\n",
    "print(\"The shape of the numpy array of class second images\", class_3_images.shape)\n",
    "print(\"The shape of the numpy array of class second images\", class_4_images.shape)\n",
    "\n",
    "print(\"The shape of the numpy array of custom images\", custom_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the score for each image\n",
    "\n",
    "# scores stores a list of scores for each custom image with the train dataset\n",
    "scores = list()\n",
    "\n",
    "# labels is a list of labels for each custom image against the class label of trained image\n",
    "labels = list()\n",
    "\n",
    "# looping through all custom images\n",
    "for image in custom_images:\n",
    "    label = list()\n",
    "    score = list()\n",
    "    # looping across images of class 1\n",
    "    for sample in class_1_images :\n",
    "        image , sample = image.reshape( ( 1 , -1 ) ) , sample.reshape((1 , -1 ) )\n",
    "        score.append( recognizer.predict( [ image , sample ])[0] )\n",
    "        # appending label 0 to this class\n",
    "        label.append( 0 )\n",
    "    # looping across images of class 2\n",
    "    for sample in class_2_images :\n",
    "        image , sample = image.reshape( ( 1 , -1 ) ) , sample.reshape((1 , -1 ) )\n",
    "        score.append( recognizer.predict( [ image , sample ])[0] )\n",
    "        # appending label 1 for this class\n",
    "        label.append( 1 )\n",
    "    # looping across images of class 3\n",
    "    for sample in class_3_images :\n",
    "        image , sample = image.reshape( ( 1 , -1 ) ) , sample.reshape((1 , -1 ) )\n",
    "        score.append( recognizer.predict( [ image , sample ])[0] )\n",
    "        # appending label 1 for this class\n",
    "        label.append( 2 )\n",
    "    # looping across images of class 4\n",
    "    for sample in class_4_images :\n",
    "        image , sample = image.reshape( ( 1 , -1 ) ) , sample.reshape((1 , -1 ) )\n",
    "        score.append( recognizer.predict( [ image , sample ])[0] )\n",
    "        # appending label 1 for this class\n",
    "        label.append( 3 )\n",
    "#     # looping across images of class 5\n",
    "#     for sample in class_5_images :\n",
    "#         image , sample = image.reshape( ( 1 , -1 ) ) , sample.reshape((1 , -1 ) )\n",
    "#         score.append( recognizer.predict( [ image , sample ])[0] )\n",
    "#         # appending label 1 for this class\n",
    "#         label.append( 4 )\n",
    "    labels.append( label )\n",
    "    scores.append( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the scores and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores are:  [[array([0.36300611], dtype=float32), array([0.36300611], dtype=float32), array([0.43088087], dtype=float32), array([0.48405963], dtype=float32), array([0.38549522], dtype=float32), array([0.26712358], dtype=float32), array([0.2863428], dtype=float32), array([0.26712358], dtype=float32), array([0.26712358], dtype=float32), array([0.2863428], dtype=float32), array([0.37838963], dtype=float32), array([0.37838963], dtype=float32), array([0.37838963], dtype=float32), array([0.37838963], dtype=float32), array([0.37838963], dtype=float32), array([0.2268976], dtype=float32), array([0.2268976], dtype=float32), array([0.23803928], dtype=float32), array([0.24418685], dtype=float32), array([0.2268976], dtype=float32)], [array([0.17776689], dtype=float32), array([0.17776689], dtype=float32), array([0.22313863], dtype=float32), array([0.22704044], dtype=float32), array([0.16415888], dtype=float32), array([0.46099502], dtype=float32), array([0.4372353], dtype=float32), array([0.46099502], dtype=float32), array([0.46099502], dtype=float32), array([0.4372353], dtype=float32), array([0.33867282], dtype=float32), array([0.33867282], dtype=float32), array([0.33867282], dtype=float32), array([0.33867282], dtype=float32), array([0.33867282], dtype=float32), array([0.3219772], dtype=float32), array([0.3219772], dtype=float32), array([0.49946404], dtype=float32), array([0.30137628], dtype=float32), array([0.3219772], dtype=float32)], [array([0.1678052], dtype=float32), array([0.1678052], dtype=float32), array([0.21128783], dtype=float32), array([0.24923342], dtype=float32), array([0.1816498], dtype=float32), array([0.44372714], dtype=float32), array([0.46754655], dtype=float32), array([0.44372714], dtype=float32), array([0.44372714], dtype=float32), array([0.46754655], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.2958594], dtype=float32), array([0.2958594], dtype=float32), array([0.46890584], dtype=float32), array([0.3162539], dtype=float32), array([0.2958594], dtype=float32)], [array([0.19989622], dtype=float32), array([0.19989622], dtype=float32), array([0.24920425], dtype=float32), array([0.2534132], dtype=float32), array([0.18497539], dtype=float32), array([0.4970676], dtype=float32), array([0.4730805], dtype=float32), array([0.4970676], dtype=float32), array([0.4970676], dtype=float32), array([0.4730805], dtype=float32), array([0.30707663], dtype=float32), array([0.30707663], dtype=float32), array([0.30707663], dtype=float32), array([0.30707663], dtype=float32), array([0.30707663], dtype=float32), array([0.29125264], dtype=float32), array([0.29125264], dtype=float32), array([0.46337777], dtype=float32), array([0.27182943], dtype=float32), array([0.29125264], dtype=float32)], [array([0.1678052], dtype=float32), array([0.1678052], dtype=float32), array([0.21128783], dtype=float32), array([0.24923342], dtype=float32), array([0.1816498], dtype=float32), array([0.44372714], dtype=float32), array([0.46754655], dtype=float32), array([0.44372714], dtype=float32), array([0.44372714], dtype=float32), array([0.46754655], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.3544575], dtype=float32), array([0.2958594], dtype=float32), array([0.2958594], dtype=float32), array([0.46890584], dtype=float32), array([0.3162539], dtype=float32), array([0.2958594], dtype=float32)], [array([0.26303667], dtype=float32), array([0.26303667], dtype=float32), array([0.3216581], dtype=float32), array([0.37012348], dtype=float32), array([0.282075], dtype=float32), array([0.31065327], dtype=float32), array([0.33158737], dtype=float32), array([0.31065327], dtype=float32), array([0.31065327], dtype=float32), array([0.33158737], dtype=float32), array([0.49287927], dtype=float32), array([0.49287927], dtype=float32), array([0.49287927], dtype=float32), array([0.49287927], dtype=float32), array([0.49287927], dtype=float32), array([0.19183794], dtype=float32), array([0.19183794], dtype=float32), array([0.33279845], dtype=float32), array([0.20717165], dtype=float32), array([0.19183794], dtype=float32)], [array([0.3370539], dtype=float32), array([0.3370539], dtype=float32), array([0.2767715], dtype=float32), array([0.28127155], dtype=float32), array([0.31593782], dtype=float32), array([0.2666986], dtype=float32), array([0.24833912], dtype=float32), array([0.2666986], dtype=float32), array([0.2666986], dtype=float32), array([0.24833912], dtype=float32), array([0.40557742], dtype=float32), array([0.40557742], dtype=float32), array([0.40557742], dtype=float32), array([0.40557742], dtype=float32), array([0.40557742], dtype=float32), array([0.26276714], dtype=float32), array([0.26276714], dtype=float32), array([0.2979155], dtype=float32), array([0.24458802], dtype=float32), array([0.26276714], dtype=float32)], [array([0.2768711], dtype=float32), array([0.2768711], dtype=float32), array([0.22372007], dtype=float32), array([0.22762883], dtype=float32), array([0.2580578], dtype=float32), array([0.3373399], dtype=float32), array([0.31621444], dtype=float32), array([0.3373399], dtype=float32), array([0.3373399], dtype=float32), array([0.31621444], dtype=float32), array([0.224309], dtype=float32), array([0.224309], dtype=float32), array([0.224309], dtype=float32), array([0.224309], dtype=float32), array([0.224309], dtype=float32), array([0.4437722], dtype=float32), array([0.4437722], dtype=float32), array([0.36039287], dtype=float32), array([0.4202081], dtype=float32), array([0.4437722], dtype=float32)]]\n",
      "The labels are:  [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]]\n",
      "The shape of the numpy array of labels are:  (8, 20, 1)\n",
      "The shape of the numpy array of scores are: (8, 20)\n",
      "The scores are:  [[[0.36300611]\n",
      "  [0.36300611]\n",
      "  [0.43088087]\n",
      "  [0.48405963]\n",
      "  [0.38549522]\n",
      "  [0.26712358]\n",
      "  [0.2863428 ]\n",
      "  [0.26712358]\n",
      "  [0.26712358]\n",
      "  [0.2863428 ]\n",
      "  [0.37838963]\n",
      "  [0.37838963]\n",
      "  [0.37838963]\n",
      "  [0.37838963]\n",
      "  [0.37838963]\n",
      "  [0.2268976 ]\n",
      "  [0.2268976 ]\n",
      "  [0.23803928]\n",
      "  [0.24418685]\n",
      "  [0.2268976 ]]\n",
      "\n",
      " [[0.17776689]\n",
      "  [0.17776689]\n",
      "  [0.22313863]\n",
      "  [0.22704044]\n",
      "  [0.16415888]\n",
      "  [0.46099502]\n",
      "  [0.4372353 ]\n",
      "  [0.46099502]\n",
      "  [0.46099502]\n",
      "  [0.4372353 ]\n",
      "  [0.33867282]\n",
      "  [0.33867282]\n",
      "  [0.33867282]\n",
      "  [0.33867282]\n",
      "  [0.33867282]\n",
      "  [0.3219772 ]\n",
      "  [0.3219772 ]\n",
      "  [0.49946404]\n",
      "  [0.30137628]\n",
      "  [0.3219772 ]]\n",
      "\n",
      " [[0.1678052 ]\n",
      "  [0.1678052 ]\n",
      "  [0.21128783]\n",
      "  [0.24923342]\n",
      "  [0.1816498 ]\n",
      "  [0.44372714]\n",
      "  [0.46754655]\n",
      "  [0.44372714]\n",
      "  [0.44372714]\n",
      "  [0.46754655]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.2958594 ]\n",
      "  [0.2958594 ]\n",
      "  [0.46890584]\n",
      "  [0.3162539 ]\n",
      "  [0.2958594 ]]\n",
      "\n",
      " [[0.19989622]\n",
      "  [0.19989622]\n",
      "  [0.24920425]\n",
      "  [0.2534132 ]\n",
      "  [0.18497539]\n",
      "  [0.4970676 ]\n",
      "  [0.4730805 ]\n",
      "  [0.4970676 ]\n",
      "  [0.4970676 ]\n",
      "  [0.4730805 ]\n",
      "  [0.30707663]\n",
      "  [0.30707663]\n",
      "  [0.30707663]\n",
      "  [0.30707663]\n",
      "  [0.30707663]\n",
      "  [0.29125264]\n",
      "  [0.29125264]\n",
      "  [0.46337777]\n",
      "  [0.27182943]\n",
      "  [0.29125264]]\n",
      "\n",
      " [[0.1678052 ]\n",
      "  [0.1678052 ]\n",
      "  [0.21128783]\n",
      "  [0.24923342]\n",
      "  [0.1816498 ]\n",
      "  [0.44372714]\n",
      "  [0.46754655]\n",
      "  [0.44372714]\n",
      "  [0.44372714]\n",
      "  [0.46754655]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.3544575 ]\n",
      "  [0.2958594 ]\n",
      "  [0.2958594 ]\n",
      "  [0.46890584]\n",
      "  [0.3162539 ]\n",
      "  [0.2958594 ]]\n",
      "\n",
      " [[0.26303667]\n",
      "  [0.26303667]\n",
      "  [0.3216581 ]\n",
      "  [0.37012348]\n",
      "  [0.282075  ]\n",
      "  [0.31065327]\n",
      "  [0.33158737]\n",
      "  [0.31065327]\n",
      "  [0.31065327]\n",
      "  [0.33158737]\n",
      "  [0.49287927]\n",
      "  [0.49287927]\n",
      "  [0.49287927]\n",
      "  [0.49287927]\n",
      "  [0.49287927]\n",
      "  [0.19183794]\n",
      "  [0.19183794]\n",
      "  [0.33279845]\n",
      "  [0.20717165]\n",
      "  [0.19183794]]\n",
      "\n",
      " [[0.3370539 ]\n",
      "  [0.3370539 ]\n",
      "  [0.2767715 ]\n",
      "  [0.28127155]\n",
      "  [0.31593782]\n",
      "  [0.2666986 ]\n",
      "  [0.24833912]\n",
      "  [0.2666986 ]\n",
      "  [0.2666986 ]\n",
      "  [0.24833912]\n",
      "  [0.40557742]\n",
      "  [0.40557742]\n",
      "  [0.40557742]\n",
      "  [0.40557742]\n",
      "  [0.40557742]\n",
      "  [0.26276714]\n",
      "  [0.26276714]\n",
      "  [0.2979155 ]\n",
      "  [0.24458802]\n",
      "  [0.26276714]]\n",
      "\n",
      " [[0.2768711 ]\n",
      "  [0.2768711 ]\n",
      "  [0.22372007]\n",
      "  [0.22762883]\n",
      "  [0.2580578 ]\n",
      "  [0.3373399 ]\n",
      "  [0.31621444]\n",
      "  [0.3373399 ]\n",
      "  [0.3373399 ]\n",
      "  [0.31621444]\n",
      "  [0.224309  ]\n",
      "  [0.224309  ]\n",
      "  [0.224309  ]\n",
      "  [0.224309  ]\n",
      "  [0.224309  ]\n",
      "  [0.4437722 ]\n",
      "  [0.4437722 ]\n",
      "  [0.36039287]\n",
      "  [0.4202081 ]\n",
      "  [0.4437722 ]]]\n",
      "The lables are:  [[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The scores are: \", scores)\n",
    "print(\"The labels are: \", labels)\n",
    "\n",
    "scores = np.array( scores )\n",
    "labels = np.array( labels )\n",
    "\n",
    "print('The shape of the numpy array of labels are: ', scores.shape)\n",
    "print('The shape of the numpy array of scores are:', labels.shape )\n",
    "print('The scores are: ', scores)\n",
    "print('The lables are: ', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying into classes based on best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE 1 is 0 with confidence of 0.4840596318244934\n",
      "IMAGE 2 is 3 with confidence of 0.4994640350341797\n",
      "IMAGE 3 is 3 with confidence of 0.46890583634376526\n",
      "IMAGE 4 is 1 with confidence of 0.4970676004886627\n",
      "IMAGE 5 is 3 with confidence of 0.46890583634376526\n",
      "IMAGE 6 is 2 with confidence of 0.4928792715072632\n",
      "IMAGE 7 is 2 with confidence of 0.4055774211883545\n",
      "IMAGE 8 is 3 with confidence of 0.44377219676971436\n"
     ]
    }
   ],
   "source": [
    "for i in range( custom_images.shape[0] ) :\n",
    "    index = np.argmax( scores[i] )\n",
    "    label_ = labels[i][index]\n",
    "    print( 'IMAGE {} is {} with confidence of {}'.format( i+1  , label_ , scores[i][index][0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
